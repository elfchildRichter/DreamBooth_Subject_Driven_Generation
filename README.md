UC Boulder MSDS course work <br>
DTSA 5511 Deep Learning <br>

## Project <br> DreamBooth_Subject_Driven_Generation


This [repo](https://github.com/elfchildRichter/DreamBooth_Subject_Driven_Generation/tree/main) employs DreamBooth to fine-tune the Stable Diffusion model, enabling the generation of images with a specific target subject in diverse scenes. 

**DreamBooth** achieves this by learning from a few instance images to capture and replicate the unique traits of a subject. It determines a specific direction within the generator's latent space, allowing the model to integrate a unique identifier associated with the subject, while preserving the rest of the textual elements.

Here the instance images used are photos of a particular white cat, and the class images were produced using Stable Diffusion before the tuning process.

|Label | Train Images |
| --- | ---|
| instance images <br> unique_id = 'miru' | <img src='train_imgs/img_miru_6.png' width=400>|
| class images <br> class_label = 'cat' | <img src='train_imgs/img_cat_6.png' width=400>|

<br>

Four models were tuned with combinations of learning_rate and max_train_steps. Each model generated images with three different settings of num_steps and unconditional_guidance_scale.

<br>

| Attribute          | Model 1 | Model 2 | Model 3 | Model 4 |
|--------------------|---------|---------|---------|---------|
| Learning Rate      | 1e-6    | 1e-6    | 3e-6    | 3e-6    |
| Max Train Steps    | 600     | 900     | 600     | 900     |
| steps = 30 <br> ugs = 6    | <img src='generated_imgs/img_1e-6_600_30_6.png' width=200>| <img src='generated_imgs/img_1e-6_900_30_6.png' width=200>| <img src='generated_imgs/img_3e-6_600_30_6.png' width=200> | <img src='generated_imgs/img_3e-6_900_30_6.png' width=200> |
| steps = 30 <br> ugs = 12   | <img src='generated_imgs/img_1e-6_600_30_12.png' width=200> | <img src='generated_imgs/img_1e-6_900_30_12.png' width=200> | <img src='generated_imgs/img_3e-6_600_30_12.png' width=200> | <img src='generated_imgs/img_3e-6_900_30_12.png' width=200> |
| steps = 50 <br> ugs = 12   | <img src='generated_imgs/img_1e-6_600_50_12.png' width=200> | <img src='generated_imgs/img_1e-6_900_50_12.png' width=200>  | <img src='generated_imgs/img_3e-6_600_50_12.png' width=200> | <img src='generated_imgs/img_3e-6_900_50_12.png' width=200> |

prompt = 'a photo of miru cat by the sea'

<br>

For this task, a learning rate of 3e-6 is deemed relatively more appropriate, observing that the loss decreases as the number of training epochs increases. Additionally, when steps are set to 900, the model  attains the lowest observed loss value of 0.0894. The Model 4 is the most effective among the four tuned models.

After experimenting with different combinations of steps and ugs, setting them to 50 and 12, respectively, can generate images that are not overfitted and achieve a suitable balance between instance image fidelity and image quality.

<br>

| Prompt | Model 4: lr_rate=3e-6, max_train_steps=900, steps=50, ugs=12 |
|--- |--- |
| 'a photo of miru cat by the sea' | <img src='generated_imgs/model_4_sea.png' width=600> |
| 'a  photo of miru cat in the forest' | <img src='generated_imgs/model_4_forest.png' width=600>|
| 'a photo of miru cat in Jiufen' | <img src='generated_imgs/model_4_jiufen.png' width=600>|
| 'a photo of miru cat on a gondola in venice' | <img src='generated_imgs/model_4_gondola.png' width=600>|

Images generated by model 4 with different prompts.

<br>

Subsequently, attempting more precise tuning and adjustments to additional parameters, or fine-tuning to the text encoder, all have a high probability of improving the overall model to better suit this task.

<br>


### Reference

- [Fine Tuning Text-to-Image Diffusion Models for Subject-Driven Generation](https://arxiv.org/abs/2208.12242)
- [Training Stable Diffusion with Dreambooth using Diffusers](https://huggingface.co/blog/dreambooth)
- [Hugging Face DreamBooth](https://huggingface.co/docs/diffusers/training/dreambooth)
- [Keras/Code examples/DreamBooth](https://keras.io/examples/generative/dreambooth/)
- [DreamBooth training example](https://github.com/huggingface/diffusers/tree/main/examples/dreambooth)
- [Fine-tuning Stable Diffusion](https://keras.io/examples/generative/finetune_stable_diffusion/)




